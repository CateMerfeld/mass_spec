{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv('/home/cmdunham/mass_spec/mass_spec_repo/data/MoNA_embeddings_multiple_instrument_types.csv')\n",
    "spectra = pd.read_csv('/home/cmdunham/mass_spec/mass_spec_repo/data/scaled_spectra_with_instrument_type.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_sections(spectra, embeddings, columns, batch_size=32, noise = None):\n",
    "  \n",
    "    \"\"\"\n",
    "    Given a list of column names, return a DataLoader object with data for those columns\n",
    "\n",
    "    Args:\n",
    "    - spectra (pd.DataFrame): Mass spec data with observations as columns.\n",
    "    - embeddings (pd.DataFrame): Column headers are chemical names. Each column represents one chemical's Chemception embedding.\n",
    "    - columns (list): Column names to be included in the dataset \n",
    "    - noise (str): Location for noise in the dataset - 'spectrum', 'embedding' or 'condition'\n",
    "    \n",
    "    Returns:\n",
    "    Tuple:\n",
    "    - train_input (DataLoader object): spectrum, encoding information and embedding, labels - chem names\n",
    "    - test_input (DataLoader object): spectrum, encoding information and embedding, labels - chem names\n",
    "    \"\"\"\n",
    "\n",
    "    labels = []\n",
    "    selected_embeddings = []\n",
    "    for col in columns:\n",
    "        embedding = embeddings[col.split('.')[0]]\n",
    "        if noise == 'embedding':\n",
    "            selected_embeddings.append([0 for _ in range(embedding.shape[0])])\n",
    "        else:\n",
    "            selected_embeddings.append(embedding)\n",
    "        # label is chemical name encoding\n",
    "        labels.append(list(spectra[col][915:-12]))\n",
    "\n",
    "    # combine spectrum data, condition encoding and chemception embedding\n",
    "    spectrum_data = spectra[list(columns)][:915].values\n",
    "    if noise == 'spectrum':\n",
    "        spectrum_data = np.zeros_like(spectrum_data)\n",
    "    condition_encodings = spectra[list(columns)][-12:].values\n",
    "    if noise == 'condition':\n",
    "        condition_encodings = np.zeros_like(condition_encodings)\n",
    "    selected_embeddings = torch.tensor(selected_embeddings).T\n",
    "    labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    input_data = torch.tensor(np.vstack((spectrum_data, condition_encodings, selected_embeddings)).T, dtype=torch.float)\n",
    "    input_data = TensorDataset(input_data, labels)\n",
    "    input_data = DataLoader(dataset=input_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Chem names + instrument encodings as labels\n",
    "\n",
    "def create_dataset(spectra, embeddings, test_chem = 'Succinic Acid', instrument_idx = 8, batch_size=32, training_chems = None, noise = None):\n",
    "  \"\"\"\n",
    "  Clean and format data\n",
    "\n",
    "  Args:\n",
    "  - spectra (pd.DataFrame): Mass spec data with observations as columns.\n",
    "  - embeddings (pd.DataFrame): Column headers are chemical names. Each column represents one chemical's Chemception embedding.\n",
    "  - instrument_idx: (int) Encoded index of instrument to be set aside for testing\n",
    "  - batch_size: (int) Batch size to use for training\n",
    "  - training_chems: (list) When training small group models this param can be used to specify which chems to include in the dataset\n",
    "  - noise: (str) 'spectrum', 'embedding' or 'condition' - Location for noise in the dataset\n",
    "  Returns:\n",
    "    Tuple:\n",
    "    - train_input (DataLoader object): true spectrum, encoding information and 512 0s to be filled with embedding, labels - chem names\n",
    "    - train_comparison (DataLoader object): true spectrum, encoding information and true embedding, labels - chem names\n",
    "    - test_input (DataLoader object): blank spectrum to be filled in, encoding information and true embedding, labels - chem names\n",
    "    - test_comparison (DataLoader object): true spectrum, encoding information and true embedding, labels - chem names\n",
    "  \"\"\"\n",
    "  all_test_chem_columns = [col for col in spectra.columns if test_chem in col]\n",
    "\n",
    "  # separate specified chemical and instrument type for testing  \n",
    "  test_cols = []\n",
    "  for col in all_test_chem_columns:\n",
    "    instrument_encoding = list(spectra[col][-12:])\n",
    "    # filter out the test instrument type\n",
    "    if instrument_encoding.index(1) == instrument_idx:\n",
    "      test_cols.append(col)\n",
    "\n",
    "  non_test_cols = set(spectra.columns) - set(test_cols)\n",
    "  # use either specified chemicals (for small group training) or everything except test cols for training data\n",
    "  if training_chems:\n",
    "    train_cols = [col for col in non_test_cols if col.split('.')[0] in training_chems]\n",
    "  else:\n",
    "    train_cols = non_test_cols\n",
    "\n",
    "  train_input = create_dataset_sections(spectra, embeddings, train_cols, batch_size=batch_size, noise=noise)\n",
    "  test_input = create_dataset_sections(spectra, embeddings, test_cols, batch_size=batch_size, noise=None)\n",
    "\n",
    "  return train_input, test_input\n",
    "\n",
    "\n",
    "train_input, test_input = create_dataset(spectra, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Chem names + instrument encodings as labels\n",
    "\n",
    "def create_dataset(spectra, embeddings, test_chem = 'Succinic Acid', instrument_idx = 8, batch_size=32, training_chems = None, noise = None):\n",
    "  \"\"\"\n",
    "  Clean and format data\n",
    "\n",
    "  Args:\n",
    "  - spectra (pd.DataFrame): Mass spec data with observations as columns.\n",
    "  - embeddings (pd.DataFrame): Column headers are chemical names. Each column represents one chemical's Chemception embedding.\n",
    "  - instrument_idx: (int) Encoded index of instrument to be set aside for testing\n",
    "  - batch_size: (int) Batch size to use for training\n",
    "  - training_chems: (list) When training small group models this param can be used to specify which chems to include in the dataset\n",
    "  - noise: (str) 'spectrum', 'embedding' or 'condition' - Location for noise in the dataset\n",
    "  Returns:\n",
    "    Tuple:\n",
    "    - train_input (DataLoader object): true spectrum, encoding information and 512 0s to be filled with embedding, labels - chem names\n",
    "    - train_comparison (DataLoader object): true spectrum, encoding information and true embedding, labels - chem names\n",
    "    - test_input (DataLoader object): blank spectrum to be filled in, encoding information and true embedding, labels - chem names\n",
    "    - test_comparison (DataLoader object): true spectrum, encoding information and true embedding, labels - chem names\n",
    "  \"\"\"\n",
    "  all_test_chem_columns = [col for col in spectra.columns if test_chem in col]\n",
    "\n",
    "  # separate specified chemical and instrument type for testing  \n",
    "  test_cols = []\n",
    "  test_labels = []\n",
    "  test_embeddings = []\n",
    "  # test_blank_embeddings = []\n",
    "  for col in all_test_chem_columns:\n",
    "    instrument_encoding = list(spectra[col][-12:])\n",
    "    # filter out the test instrument type\n",
    "    if instrument_encoding.index(1) == instrument_idx:\n",
    "      embedding = embeddings[col.split('.')[0]]\n",
    "      if noise == 'embedding':\n",
    "        test_embeddings.append([0 for _ in range(embedding.shape[0])])\n",
    "      else:\n",
    "        test_embeddings.append(embedding)\n",
    "      test_cols.append(col)\n",
    "      # label is chemical name encoding\n",
    "      test_labels.append(list(spectra[col][915:-12]))\n",
    "\n",
    "  # combine spectrum data, condition encoding and chemception embedding\n",
    "  test_spectrum_data = spectra[test_cols][:915].values\n",
    "  if noise == 'spectrum':\n",
    "    test_spectrum_data = np.zeros_like(test_spectrum_data)\n",
    "  test_condition_encodings = spectra[test_cols][-12:].values\n",
    "  if noise == 'condition':\n",
    "    test_condition_encodings = np.zeros_like(test_condition_encodings)\n",
    "  test_embeddings = torch.tensor(test_embeddings).T\n",
    "  # test_blank_embeddings = torch.tensor(test_blank_embeddings).T\n",
    "  test_labels = torch.tensor(test_labels, dtype=torch.float)\n",
    "  \n",
    "  test_input_data = torch.tensor(np.vstack((test_spectrum_data, test_condition_encodings, test_embeddings)).T, dtype=torch.float)\n",
    "  test_input = TensorDataset(test_input_data, test_labels)\n",
    "  test_input = DataLoader(dataset=test_input, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  # test_comparison_data = torch.tensor(np.vstack((test_spectrum_data, test_condition_encodings, test_blank_embeddings)).T, dtype=torch.float)\n",
    "  # test_comparison = TensorDataset(test_comparison_data, test_labels)\n",
    "  # test_comparison = DataLoader(dataset=test_comparison, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  non_test_cols = set(spectra.columns) - set(test_cols)\n",
    "  # use either specified chemicals (for small group training) or everything except test cols for training data\n",
    "  if training_chems:\n",
    "    train_cols = [col for col in non_test_cols if col.split('.')[0] in training_chems]\n",
    "  else:\n",
    "    train_cols = non_test_cols\n",
    "\n",
    "  train_labels = []\n",
    "  train_embeddings = []\n",
    "  train_blank_embeddings = []\n",
    "  for col in train_cols:\n",
    "    train_labels.append(list(spectra[col][915:-12]))\n",
    "    train_embeddings.append(embeddings[col.split('.')[0]])\n",
    "    train_blank_embeddings.append([0 for _ in range(embedding.shape[0])])\n",
    "\n",
    "  train_spectrum_data = spectra[list(train_cols)][:915].values\n",
    "  train_condition_encodings = spectra[list(train_cols)][-12:].values\n",
    "  train_embeddings = torch.tensor(train_embeddings).T\n",
    "  train_blank_embeddings = torch.tensor(train_blank_embeddings).T\n",
    "  train_labels = torch.tensor(train_labels, dtype=torch.float)\n",
    "\n",
    "  input_data = torch.tensor(np.vstack((train_spectrum_data, train_condition_encodings, train_embeddings)).T, dtype=torch.float)\n",
    "  train_input = TensorDataset(input_data, train_labels)\n",
    "  train_input = DataLoader(dataset=train_input, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  # train_comparison_data = torch.tensor(np.vstack((train_spectrum_data, train_condition_encodings, train_blank_embeddings)).T, dtype=torch.float)\n",
    "  # train_comparison = TensorDataset(train_comparison_data, train_labels)\n",
    "  # train_comparison = DataLoader(dataset=train_comparison, batch_size=batch_size, shuffle=True)\n",
    "  return train_input, test_input\n",
    "\n",
    "\n",
    "thing, stuff = create_dataset(spectra, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1439"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, learning_rate):\n",
    "    super().__init__()\n",
    "\n",
    "    self.encoder = nn.Sequential(\n",
    "      nn.Linear(1439,878),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Linear(878,841),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Linear(841,804),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Linear(804,767),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Linear(767, 730),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Linear(730, 693),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Linear(693, 656),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Linear(656, 619),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Linear(619, 582),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Linear(582, 545),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Linear(545, 1439),\n",
    "    )\n",
    "\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(), lr = learning_rate)\n",
    "    self.criterion = nn.MSELoss()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.encoder(x)\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mass_spec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
