{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchmetrics.regression import PearsonCorrCoef\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_df = pd.read_csv('/home/cmdunham/mass_spec/mass_spec_repo/data/scaled_spectra_with_instrument_type.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Function Definitions:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_cosine_similarity(output, target):\n",
    "  # it is common to use m/z ratio as weights since fragments with higher m/z ratios are more important.\n",
    "  mz = torch.arange(1, len(target)+1)\n",
    "\n",
    "  numerator = torch.sum(mz*output*target)\n",
    "  output_denom = torch.sqrt(torch.sum(mz*output**2))\n",
    "  target_denom = torch.sqrt(torch.sum(mz*target**2))\n",
    "\n",
    "  weighted_cosine_similarity = numerator/(output_denom*target_denom)\n",
    "  return(weighted_cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(real_spectra, fake_spectra, labels, idx=[0,5], window=300, cutoff = 0.5):\n",
    "  \"\"\"\n",
    "  Plot and compare real and synthetic spectra within a specified index range.\n",
    "\n",
    "  Takes in real, noisy, and synthetic spectra and plots them for comparison.\n",
    "  Computes and prints the weighted cosine similarity between the real spectrum and \n",
    "  both the noisy and synthetic spectra.\n",
    "\n",
    "  Args:\n",
    "      real_spectra (list of list of float): List of real spectra, where each spectrum is a list of intensity values.\n",
    "      fake_spectra (list of list of float): List of synthetic spectra generated by decoder.\n",
    "      labels (list of str): List of chemical name labels corresponding to each spectrum.\n",
    "      idx (list of int, optional): Range of indices to plot. Default is [0, 10].\n",
    "      window (int, optional): Highest m/z to plot for each spectrum. Default is 300.\n",
    "      cutoff (float, optional): Intensity cutoff threshold to filter out low-intensity noise. Default is 0.5.\n",
    "  \"\"\"\n",
    "  for i, (real_spec, fake_spec) in enumerate(zip(real_spectra, fake_spectra)):\n",
    "    # only plot spectra within the specified index range\n",
    "    if i > idx[1]:\n",
    "      break\n",
    "    if idx[0] <= i < idx[1]:\n",
    "      # Define the x-axis range\n",
    "      numbers = range(0, window)\n",
    "      \n",
    "      # Scale the real spectrum so highest peak is 100\n",
    "      input_frequencies = real_spec.copy()\n",
    "      input_max = max(input_frequencies)\n",
    "      scaled_input = [num/input_max * 100 for num in input_frequencies]\n",
    "\n",
    "      # Scale the synthetic spectrum so highest peak is 100\n",
    "      out_clone = fake_spec.copy()\n",
    "      output_max = max(out_clone)\n",
    "      scaled_out = [num/output_max * 100 for num in out_clone]\n",
    "      out_frequencies = [0 if num < cutoff else num for num in scaled_out]\n",
    "\n",
    "      weighted_cosine_similarity = get_weighted_cosine_similarity(out_clone, input_frequencies)\n",
    "\n",
    "      # Create a plot with 2 subplots for real and synthetic spectra\n",
    "      _, ax = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True, figsize=(20, 10))\n",
    "\n",
    "      ax[0].bar(numbers, scaled_input[:window])\n",
    "      ax[0].set_title(f'True {labels[i]} Spectrum.', fontsize=18)\n",
    "      ax[0].set_xlabel('Mass to Charge Ratio', fontsize=16)\n",
    "      ax[0].set_ylabel('Intensity', fontsize=16)\n",
    "\n",
    "      ax[1].bar(numbers, out_frequencies[:window])\n",
    "      ax[1].set_title(f'Synthetic {labels[i]} Spectrum.', fontsize=18)\n",
    "      print('Weighted cosine similarity between true spectrum and output spectrum is: ', round(float(weighted_cosine_similarity), 2))\n",
    "      ax[1].set_xlabel('Mass to Charge Ratio', fontsize=16)\n",
    "      ax[1].set_ylabel('Intensity', fontsize=16)\n",
    "\n",
    "      plt.tight_layout()\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition:\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE based on model from this paper: https://ieeexplore.ieee.org/abstract/document/10463452\n",
    "\n",
    "Using this tutorial for help: https://medium.com/@rekalantar/variational-auto-encoder-vae-pytorch-tutorial-dce2d2fe0f5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "  \"\"\"\n",
    "    Variational Autoencoder (VAE) class implementation.\n",
    "\n",
    "    The VAE consists of an encoder that maps input data to a latent space\n",
    "    and a decoder that reconstructs the data from the latent space. The latent\n",
    "    space is characterized by a mean and log variance, which are used to sample\n",
    "    latent vectors.\n",
    "\n",
    "    Attributes:\n",
    "        encoder (nn.Sequential): Neural network to encode input data into a latent space.\n",
    "        mean_layer (nn.Linear): Linear layer to compute the mean of the latent space.\n",
    "        logvar_layer (nn.Linear): Linear layer to compute the log variance of the latent space.\n",
    "        decoder (nn.Sequential): Neural network to decode latent vectors back into the data space.\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.encoder = nn.Sequential(\n",
    "      nn.Linear(915,819),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(819, 723),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(723, 627),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(627,531),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(531,435),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(435,339),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(339,243),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(243,147),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(147,100),\n",
    "    )\n",
    "\n",
    "    self.mean_layer = nn.Linear(100, 2)\n",
    "    self.logvar_layer = nn.Linear(100, 2)\n",
    "\n",
    "    self.decoder = nn.Sequential(\n",
    "      nn.Linear(2,98),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(98,194),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(194,290),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(290,386),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(386,482),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(482,578),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(578,674),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(674,770),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(770,866),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(866,915),\n",
    "    )\n",
    "  \n",
    "  def encode(self, x):\n",
    "    x = self.encoder(x)\n",
    "    mean, logvar = self.mean_layer(x), self.logvar_layer(x)\n",
    "    return mean, logvar\n",
    "\n",
    "  def reparameterization(self, mean, log_var):\n",
    "    eps = torch.randn_like(log_var)\n",
    "    z = mean + log_var * eps\n",
    "    return z\n",
    "  \n",
    "  def decode(self, z):\n",
    "    return self.decoder(z)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    mean, logvar = self.encode(x)\n",
    "    z = self.reparameterization(mean, logvar)\n",
    "    x_hat = self.decode(z)\n",
    "    return x_hat, mean, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_dataset(true_spec_data, spectra_names, test_chem = 'Succinic Acid', test_condition=8):\n",
    "#     true_spectra_train = []\n",
    "#     train_name_encodings = []\n",
    "\n",
    "#     true_spectra_test = []\n",
    "#     test_name_encodings = []\n",
    "\n",
    "#     spectra_copy = true_spec_data.copy()\n",
    "\n",
    "#     for spec, label in zip(spectra_copy, spectra_names):\n",
    "#         # default is to use same test data as in spider model, Succinic Acid on GC-EI-TOF\n",
    "#         if label == test_chem:\n",
    "#             if list(spec[-12:]).index(1) == test_condition:\n",
    "#                 true_spectra_test.append(spec[:915])\n",
    "#                 test_name_encodings.append(spec[915:965])\n",
    "#         else:\n",
    "#             true_spectra_train.append(spec[:915])\n",
    "#             train_name_encodings.append(spec[915:965])\n",
    "\n",
    "#     true_spectra_train_tensor = torch.tensor(true_spectra_train, dtype=torch.float32)\n",
    "#     train_dataset = TensorDataset(true_spectra_train_tensor, torch.tensor(train_name_encodings))\n",
    "#     train_dataset = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#     true_spectra_test_tensor = torch.tensor(true_spectra_test, dtype=torch.float32)\n",
    "#     test_dataset = TensorDataset(true_spectra_test_tensor, torch.tensor(test_name_encodings))\n",
    "#     test_dataset = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#     return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemical name encodings are currently stored between indices 915 and 965 in each data point\n",
    "chemical_encodings = torch.tensor(spectra_df[:][915:965].T.values, dtype=torch.float)\n",
    "# # removing name embeddings and condition information and truncating spectra to 650 ----------- NOT TRUNCATING CURRENTLY\n",
    "data = torch.tensor(spectra_df[:][:915].T.values, dtype=torch.float)\n",
    "x_train, x_test, train_chem_encodings, test_chem_encodings = train_test_split(data, chemical_encodings, test_size=.2, random_state = 42)\n",
    "\n",
    "sorted_chem_names = sorted(list(set(chem.split('.')[0] for chem in spectra_df.columns)))\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = DataLoader(TensorDataset(x_train, train_chem_encodings), batch_size=batch_size, shuffle=True)\n",
    "test_dataset = DataLoader(TensorDataset(x_test, test_chem_encodings), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'wandb_entity': 'catemerfeld',\n",
    "    'wandb_project': 'mass_spec',\n",
    "    'gpu':True,\n",
    "    'threads':1,\n",
    "}\n",
    "\n",
    "# Set WANDB_NOTEBOOK_NAME environment variable\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'variational_autoencoder.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_wandb(config, **kwargs):\n",
    "    config.update(kwargs)\n",
    "\n",
    "    wandb.init(entity=config['wandb_entity'],\n",
    "               project=config['wandb_project'],\n",
    "               config=config)\n",
    "\n",
    "    # Set the number of threads\n",
    "    torch.set_num_threads(config['threads'])\n",
    "\n",
    "    # Find out is there is a GPU available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if not config['gpu']:\n",
    "        device = torch.device('cpu')\n",
    "    print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create list of chemical names\n",
    "spectra_names = [chem.split('.')[0] for chem in spectra_df.columns]\n",
    "\n",
    "# # separate spectrum data from chemical name encodings\n",
    "# true_spec_data = spectra.values.T \n",
    "# encoded_names = torch.tensor(spectra[:][915:965].values, dtype=torch.float32).T\n",
    "\n",
    "# train_dataset, test_dataset = generate_dataset(true_spec_data, spectra_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch implementation from: https://discuss.pytorch.org/t/elbo-loss-in-pytorch/137431/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, x_hat, logvar, mean):\n",
    "        mse = F.mse_loss(x_hat, x)\n",
    "        kld = -0.5 * torch.sum(1+logvar - mean.pow(2) - logvar.exp())\n",
    "        return mse + kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcatemerfeld\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cmdunham/mass_spec/mass_spec_repo/establishing_baselines/wandb/run-20240607_065430-945dvf6l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/catemerfeld/mass_spec/runs/945dvf6l' target=\"_blank\">revived-disco-84</a></strong> to <a href='https://wandb.ai/catemerfeld/mass_spec' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/catemerfeld/mass_spec' target=\"_blank\">https://wandb.ai/catemerfeld/mass_spec</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/catemerfeld/mass_spec/runs/945dvf6l' target=\"_blank\">https://wandb.ai/catemerfeld/mass_spec/runs/945dvf6l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch[10/200], train loss: 17.86693\n",
      "Epoch[20/200], train loss: 16.136988\n",
      "Epoch[30/200], train loss: 14.840209\n",
      "Epoch[40/200], train loss: 15.619566\n",
      "Epoch[50/200], train loss: 14.833993\n",
      "Epoch[60/200], train loss: 13.275815\n",
      "Epoch[70/200], train loss: 242.723404\n",
      "Epoch[80/200], train loss: 16.709555\n",
      "Epoch[90/200], train loss: 14.35404\n",
      "Epoch[100/200], train loss: 13.484223\n",
      "Epoch[110/200], train loss: 13.041759\n",
      "Epoch[120/200], train loss: 13.08648\n",
      "Epoch[130/200], train loss: 13.913077\n",
      "Epoch[140/200], train loss: 13.194478\n",
      "Epoch[150/200], train loss: 13.206985\n",
      "Epoch[160/200], train loss: 12.843204\n",
      "Epoch[170/200], train loss: 11.907203\n",
      "Epoch[180/200], train loss: 15.161283\n",
      "Epoch[190/200], train loss: 12.151596\n",
      "Epoch[200/200], train loss: 18.705721\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9474845329b04738963e70b09e3e1658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Variational Autoencoder Training Loss</td><td>▇▇▇▆▄▄▃▅▄▅▃▃▃▂▆▆▅▃▃▂▂▂▃▃▂▃▃▂▃▃▂▁▂▂▁▁▁▂▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Variational Autoencoder Training Loss</td><td>18.70572</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">revived-disco-84</strong> at: <a href='https://wandb.ai/catemerfeld/mass_spec/runs/945dvf6l' target=\"_blank\">https://wandb.ai/catemerfeld/mass_spec/runs/945dvf6l</a><br/> View project at: <a href='https://wandb.ai/catemerfeld/mass_spec' target=\"_blank\">https://wandb.ai/catemerfeld/mass_spec</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240607_065430-945dvf6l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = .001\n",
    "model = VAE()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = lr)\n",
    "pearson = PearsonCorrCoef()\n",
    "criterion = VAE_loss()\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "model_output = []\n",
    "true_spectra = []\n",
    "output_labels = []\n",
    "\n",
    "training_pearson = 0\n",
    "\n",
    "config['learning_rate'] = lr\n",
    "\n",
    "run_with_wandb(config, truth='variational_autoencoder')\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch, labels in train_dataset:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        x_hat, mean, logvar = model(batch)\n",
    "        loss = criterion(x_hat, batch, logvar, mean)\n",
    "        epoch_loss += loss\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1)==epochs:\n",
    "            chem_names = [sorted(list(set(spectra_names)))[list(encoding).index(1)] for encoding in labels]\n",
    "            for output_spectrum, true_spectrum, chem_name in zip(x_hat, batch, chem_names):\n",
    "                training_pearson += pearson(output_spectrum, true_spectrum)\n",
    "                model_output.append(output_spectrum)\n",
    "                true_spectra.append(true_spectrum)\n",
    "                output_labels.append(chem_name)\n",
    "        \n",
    "    average_loss = epoch_loss/len(train_dataset)\n",
    "    wandb.log({\"Variational Autoencoder Training Loss\": average_loss})\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Epoch[{}/{}], train loss: {}'.format(epoch+1, epochs, round(float(average_loss.detach().numpy()), 6), 6))\n",
    "\n",
    "training_pearson /= len(true_spectra)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_specs = [[float(num.item()) for num in spec] for spec in [spec.detach() for spec in model_output]]\n",
    "\n",
    "# df = pd.DataFrame(save_specs).T\n",
    "# df.columns = output_labels\n",
    "# df.head()\n",
    "# df.to_csv('/home/cmdunham/mass_spec/mass_spec_repo/data/artificial_spectra_vae_one_per_training_pt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting_true_spectra = [vec.detach().numpy() for vec in true_spectra]\n",
    "# plotting_input_spectra = [vec.detach().numpy() for vec in input_spectra]\n",
    "# output_spectra = [vec.detach().numpy() for vec in model_output]\n",
    "\n",
    "# plot_results_with_input(plotting_true_spectra, plotting_input_spectra, output_spectra, output_labels, idx=[0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = tensor(19.3724)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_output = []\n",
    "test_true_spectra = []\n",
    "test_output_labels = []\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for batch, labels in test_dataset:\n",
    "        test_x_hat, test_mean, test_logvar = model(batch)\n",
    "\n",
    "        loss = criterion(test_x_hat, batch, logvar, mean)\n",
    "        test_loss+=loss\n",
    "\n",
    "        chem_names = [sorted(list(set(spectra_names)))[list(encoding).index(1)] for encoding in labels]\n",
    "        for output_spectrum, true_spectrum, chem_name in zip(test_x_hat, batch, chem_names):\n",
    "            test_output.append(output_spectrum)\n",
    "            test_true_spectra.append(true_spectrum)\n",
    "            test_output_labels.append(chem_name)\n",
    "\n",
    "    average_loss = test_loss/len(test_dataset)\n",
    "    print('Loss =', average_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1870)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_cosine_sim = 0\n",
    "\n",
    "for true_spec, synthetic_spec in zip(test_true_spectra, test_output):\n",
    "  cos_sim = get_weighted_cosine_similarity(synthetic_spec, true_spec)\n",
    "  avg_cosine_sim += cos_sim\n",
    "\n",
    "avg_cosine_sim /= len(test_output)\n",
    "avg_cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting_true_spectra = [vec.detach().numpy() for vec in test_true_spectra]\n",
    "# output_spectra = [vec.detach().numpy() for vec in test_output]\n",
    "\n",
    "# plot_results(plotting_true_spectra, output_spectra, test_output_labels, idx=[0,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_spectra_per_real = 5\n",
    "\n",
    "synthetic_spectra = []\n",
    "synthetic_spectra_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch, labels in train_dataset:\n",
    "        x_hat, mean, logvar = model(batch)\n",
    "\n",
    "        chem_names = [sorted(list(set(spectra_names)))[list(encoding).index(1)] for encoding in labels]\n",
    "        for output_spectrum, chem_name in zip(x_hat, chem_names):\n",
    "            synthetic_spectra.append(output_spectrum)\n",
    "            synthetic_spectra_labels.append(chem_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for real data: 77%\n"
     ]
    }
   ],
   "source": [
    "train_labels = [sorted_chem_names[list(encoding).index(1)] for encoding in train_chem_encodings] \n",
    "test_labels = [sorted_chem_names[list(encoding).index(1)] for encoding in test_chem_encodings]\n",
    "\n",
    "# create random forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# train and generate preds on only real spectra\n",
    "rf_classifier.fit(x_train, train_labels)\n",
    "preds = rf_classifier.predict(x_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "real_accuracy = accuracy_score(test_labels, preds)\n",
    "print(f'Accuracy Score for real data: {round((100*real_accuracy))}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for real and synthetic data: 79%\n"
     ]
    }
   ],
   "source": [
    "spectra_preds_tensor = torch.stack(synthetic_spectra)\n",
    "augmented_dataset = torch.cat((spectra_preds_tensor.clone().detach(), x_train))\n",
    "augmented_dataset_labels = synthetic_spectra_labels + train_labels\n",
    "\n",
    "# create random forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# train and generate preds on augmented dataset\n",
    "rf_classifier.fit(augmented_dataset, augmented_dataset_labels)\n",
    "preds = rf_classifier.predict(x_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "real_accuracy = accuracy_score(test_labels, preds)\n",
    "print(f'Accuracy Score for real and synthetic data: {round((100*real_accuracy))}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate ratio of predicted similarity to overall similarity:\n",
    "---\n",
    "\n",
    "Wei et. al, 2019 do this. Here's what they say about it: \n",
    "\n",
    "There is inherent noise in mass spectra due to stochasticity\n",
    "of the underlying physical process and also to experimental\n",
    "inconsistencies.9 The NIST replicates library provides multiple\n",
    "spectra for each molecule, and we can use these sets of spectra\n",
    "to characterize the scale of this noise for each molecule.\n",
    "Specifically, we define the inherent noise for a given molecule\n",
    "as the average pairwise similarity between all corresponding\n",
    "spectra, in both the NIST main library and the NIST replicates\n",
    "library, and refer to this as the overall similarity.\n",
    "For each molecule, we compute the ratio of the predicted\n",
    "similarity to overall similarity as a normalized metric for the\n",
    "quality of our predictions. A ratio of 1.0 would suggest that\n",
    "there are is limited available headroom for improvements using\n",
    "machine learning, since the model’s errors are comparable to\n",
    "the variability in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sims = {}\n",
    "# Calculate pairwise similarity between all spectra for each chemical\n",
    "for chem in sorted_chem_names:\n",
    "    chem_similarities = []\n",
    "    if not chem == '(5R,11R)-5,11-Dimethylpentacosane':# and not chem == '1,3-Diaminopropane':\n",
    "        chem_columns = list(spectra_df.filter(like=chem).columns)\n",
    "        chem_subset = spectra_df[chem_columns][:915].T.values\n",
    "\n",
    "        for i, j in combinations(range(len(chem_subset)), 2):\n",
    "            similarity = get_weighted_cosine_similarity(chem_subset[i], chem_subset[j])\n",
    "            chem_similarities.append(similarity.item())  \n",
    "        \n",
    "        average_sims[chem] = np.mean(chem_similarities)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_sims = []\n",
    "# for synthetic_spec, true_spec, chem in zip(model_output, true_spectra, output_labels):\n",
    "#     if not chem == '(5R,11R)-5,11-Dimethylpentacosane':\n",
    "#         sim = get_weighted_cosine_similarity(synthetic_spec, true_spec)\n",
    "#         sim_ratio = sim/average_sims[chem]\n",
    "#         synthetic_sims.append(sim_ratio.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "synthetic_spectra = []\n",
    "chem_labels = []\n",
    "train_true_spectra = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for batch, labels in train_dataset:\n",
    "        x_hat, mean, logvar = model(batch)\n",
    "\n",
    "        chem_names = [sorted(list(set(spectra_names)))[list(encoding).index(1)] for encoding in labels]\n",
    "        for output_spectrum, true_spectrum, chem_name in zip(test_x_hat, batch, chem_names):\n",
    "            synthetic_spectra.append(output_spectrum)\n",
    "            train_true_spectra.append(true_spectrum)\n",
    "            chem_labels.append(chem_name)\n",
    "\n",
    "thing = pd.DataFrame(synthetic_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_sims = []\n",
    "for synthetic_spec, true_spec, chem in zip(synthetic_spectra, train_true_spectra, chem_labels):\n",
    "    if not chem == '(5R,11R)-5,11-Dimethylpentacosane':\n",
    "        sim = get_weighted_cosine_similarity(synthetic_spec, true_spec)\n",
    "        sim_ratio = sim/average_sims[chem]\n",
    "        synthetic_sims.append(sim_ratio.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_synthetic_sims = {}\n",
    "\n",
    "# output_df = pd.DataFrame(model_output)\n",
    "\n",
    "# # Calculate pairwise similarity between all synthetic spectra for each chemical\n",
    "# for i, synthetic_spec, chem in enumerate(zip(model_output, output_labels)):\n",
    "#     chem_similarities = []\n",
    "#     if not chem == '(5R,11R)-5,11-Dimethylpentacosane':# and not chem == '1,3-Diaminopropane':\n",
    "#         # only want to compare spectra \n",
    "#         if chem == output_labels[i+1]: \n",
    "        \n",
    "#         average_snthetic_sims[chem] = np.mean(chem_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(synthetic_sims, bins=20, alpha=0.5, color='blue')\n",
    "\n",
    "plt.xlabel('Similarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Similarity Values')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chem_similarities = {}\n",
    "for chem in sorted_chem_names:\n",
    "    # create a subset dataset of just one chemical\n",
    "    chem_columns = list(spectra_df.filter(like=chem).columns)\n",
    "\n",
    "    chem_similarities[chem] = {}\n",
    "\n",
    "    for col in spectra_df[chem_columns]:\n",
    "        chem_similarities[chem][col] = []\n",
    "        # print(col)\n",
    "        # print('----------------')\n",
    "        chem_columns.remove(col)    \n",
    "\n",
    "        sims_list = []\n",
    "        for col2 in chem_columns:\n",
    "            # print(col2)\n",
    "            chem_similarities[chem][col].append(get_weighted_cosine_similarity(torch.tensor(spectra_df[col]), torch.tensor(spectra_df[col2])).item())\n",
    "        \n",
    "        # chem_similarities[chem][col] = sims_list\n",
    "        # print('--------------------')\n",
    "        # print(col)\n",
    "        # chem_similarities[col].append(sims_list)\n",
    "        # print(len(sims_list))\n",
    "    break\n",
    "\n",
    "len(chem_similarities['(5R,11R)-5,11-Dimethylpentacosane']['(5R,11R)-5,11-Dimethylpentacosane.1'])\n",
    "# len(list(spectra_df.filter(like='(5R,11R)-5,11-Dimethylpentacosane').columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mass_spec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
